---
title: "Exercise_3"
author: "Patrick Bigler"
date: "2023-04-24"
output: html_document
---




```{r}
df <- datasets::CO2

help("df")
summary(df)


ggplot(data = df) +
  geom_point(aes(x = conc, y = uptake, , shape = Type)) +
  labs(x = "Concentration", y = "CO2 uptake") +
  geom_smooth(aes(x = conc, y = uptake,color = Treatment, shape = Type), 
              method = "lm", formula = y~log(x))

```


first linear model

```{r}
mod.linear <- lm(uptake~conc, data = df)
summary(mod.linear)

plot(mod.linear)

```

```{r}
curve(log)
curve(x^2, xlim=c(-2,2))

mod_log <- lm(uptake ~ log(conc)+Treatment , data = df)
summary(mod_log)
```

```{r}
mod_cat <- lm(uptake~log(conc), data = df)
```


```{r}
step(object = lm(uptake ~ 1, data = df),
     scope = uptake ~ conc * log(conc) * Type * Treatment,
     direction = "forward")
```


The return of the function gives us a overview about the simple linear regression
models. 

```{r Read_the_file}
# Read the file
database <- data.frame(read_csv("../data/halfhourly_data.csv"))
```


```{r Visualization_of_the_data}
# 


```


```{r Function_for_an_overview}
# Function to determine the best fit for a single regression model
model.fitter <- function(dataframe, target.column.nr){
  # Give all column-names to a vector
  col.names <- c(colnames(dataframe))
  # Create a empty vector. We will fill it with the RR for each model
  my.vec <- c()
  aic.vec <- c()
  # For loop over all columns
  for (i in c(1 : ncol(dataframe))) {
    # If the target and the predictor the same variable RR will be 1.
    # Therefore we use a if statement
    if (i != target.column.nr){
      lm.model <- lm(unlist(dataframe[target.column.nr]) ~ unlist(dataframe[i]))
      RR <- summary(lm.model)$r.squared
      aic.vec <- c(aic.vec, extractAIC(lm.model)[2])
      my.vec <- c(my.vec, RR )
    }
    # If the target and the predictor the same, than we want RR = AIC = 0
    else{
      my.vec <- c(my.vec, NA)
      aic.vec <- c(aic.vec, NA)
    }
  }
  # We create a tibble for a proper overview
  my.tibble <- print(tibble("Target" = rep(col.names[target.column.nr], 
                                     times = ncol(dataframe)),
                      "Predictor" = col.names,
                      "RR"  = my.vec,
                      "AIC" = aic.vec,
                      "Fit" = ifelse(RR >= max(RR, na.rm = TRUE), "BEST FIT", "NO")))
  return(print(my.tibble))
}

model.fitter(database, 16)
```



```{r}
first.try <- function(dataframe,target){
  df.target <- database|>
  select(col.names[16])
  df.predictor <- database|>
  select(-col.names[16]) 
  col.names <- c(colnames(df.predictor))
  RR.now <- 0
  for (i in c(1 : ncol(df.predictor))) {
    lm.model <- lm(unlist(df.target[1]) ~ unlist(df.predictor[i]))
    RR.new <- summary(lm.model)$r.squared
  if(RR.new > RR.now){
    RR.now <- RR.new
    variable.name <- col.names[i]}
  else{}
  }
  col.names <- col.names[!col.names == variable.name]
  return(print(col.names))
}

test <- first.try(database, 16)
```


```{r}
# function to find the best model fit (step forward algorithm)

# The function needs a data.frame and the column number of the target.
multivariante.model <- function(dataframe, target){
  # Read all columns but the target and save their names in a vector
  col.names <- dataframe|>
  select(-target) |>
  colnames()
  # Start with a empty vector. Here we will write down the predictors of the best fit for each round
  predictors <- NULL
  # Start with a empty vector for the column names. Here we will write down the fittest predictor for each round
  column.name <- NULL
  # Start with a big number. While loop should run till the AIC become bigger again
  AIC.old <- 9999999
  AIC.new <- 9999998
  while (AIC.new < AIC.old) {
    # Change the watcher for the while loop. We change the watcher for each round
    AIC.old <- AIC.new
    # Set the RR value to zero. We want a new start for each round in the for loop
    RR.now <- 0
    # col.names will be shorter for each round because we delete always the best fit from the vector
    for (i in col.names) {
      # For each round, we create a new formula for the linear regression model.   
      changeable.formula <- as.formula(paste("GPP_NT_VUT_REF~", paste(c(predictors, i), collapse = "+")))
      print(changeable.formula)
      # Calculate the linear regression model
      lm.model <- lm(changeable.formula, data = database)
      # Read R^2 
      RR.new <- summary(lm.model)$r.squared
      # Search the highest R square and save the column name. We have to delete the column for the next round
      if(RR.new > RR.now){
        # Change the guard to enter the if condition
        RR.now <- RR.new
        # Extract the AIC. If the AIC bigger in the next round, we will overwrite it.
        AIC.new <- extractAIC(lm.model)[2]
        # We read the column name. If the AIC bigger for another predictor, we will overwrite it
        column.name <- as.character(i)
        } # end if condition
      # else does nothing
      else{NULL
        } # end else condition
      }# end for loop
    # Delete the name of the best fit of this round from the vector 
    col.names <- col.names[!col.names == column.name]
    # prepare the predictors for the next round
    predictors <- c(predictors, column.name)
    print(AIC.new)
    }# end while loop
# if we finished the while loop, we print our model  
print(paste("Best model fit has AIC =", AIC.old))
predictors <- predictors[-length(predictors)]
print(predictors)
return()
}

# function call
multivariante.model(database, 16)
```


tests
```{r}
test.model <- lm(GPP_NT_VUT_REF~ PPFD_IN + LW_IN_F + siteid + VPD_F + TA_F_MDS + SW_IN_F +
              WS_F + CO2_F_MDS + P_F + PA_F + TIMESTAMP + LW_IN_F_MDS + VPD_F_MDS + USTAR +
              SW_IN_F_MDS, data = database)

summary(test.model)
extractAIC(test.model)[2]
```




---
title: "Report Exercise: re_ml_02"
author: "Patrick Bigler"
date: "2023-04-24"
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
editor_options: 
  markdown: 
    wrap: 75
---

Course: Applied Geo-data Science at University of Bern (Institute of
Geography)

Supervisor: Prof. Dr. Benjamin Stocker

Adviser: Dr. Koen Hufkens, Pepa Aran, Pascal Schneider

Further information: <https://geco-bern.github.io/agds/>

[You have questions to the workflow? Contact the Author:]{.underline}

Author: Bigler Patrick
([patrick.bigler1\@students.unibe.ch](mailto:patrick.bigler1@students.unibe.ch){.email})

Matriculation number: 20-100-178

Reference: Report Exercise 7 (Chapter 10)

# Introduction

## Objectives

Here, we explore the role of structure in the data for model
generalisability and how to best estimate a \"true\" out-of-sample error
that corresponds to the prediction task. The task here is to train a model
on ecosystem flux observations from one site and predict to another site
(spatially upscaling).

-   Concept of cross validation

-   spatially upscalling

## Theory

# Method

We will not change everything for this exercise because we can reuse our
function from the last exercise (re_ml_01).

## R: Evaluation of the data

All analysis are done with the open source software R-Studio (Version
2022.12.0+353). This software use the language R to handle the data. For an
efficient processing of the data we use the R-package "Tidyverse (and
others).

# Programming and data evaluation

## Packages

The following code chunk contains all packages we need. Important is the
package "conflicted". It enables us to chose if different functions have
the same call but do not make the same thing (a function in a certain
package can have the same name as a function from another package).

```{r Load_packages, error=FALSE, message=FALSE, warning=FALSE}
source("../../R/general/packages.R")
```

## Read the file

Use the URL in the code chuck to get access to the data. We use an if/else
statement to ensure that we do not overwrite the data with every run. If
the file exists, we read it local.

```{r Load_and_read_data, error=FALSE, message=FALSE, warning=FALSE}
name.of.file <- "../../data/re_ml_02/daily_fluxes.davos.csv"

# If do not exists such a file, create it!
if (!file.exists(name.of.file)){
  # Access to the data
  url.1 <- "https://raw.githubusercontent.com/geco-bern/agds/main/data/FLX_C
  -Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv"
  # Read in the data directly from URL
  daily_fluxes.davos <- read.table(url.1, header = TRUE, sep = ",")
  # Write a CSV file in the respiratory
  write_csv(daily_fluxes.davos, "../../data/re_ml_02/daily_fluxes.davos.csv")
  # Read the file
  daily_fluxes.davos <- read_csv("../../data/re_ml_02/daily_fluxes.davos.csv")
  # If exists such a file, read it only!
  }else{daily_fluxes.davos <- read_csv("../../data/re_ml_02/daily_fluxes.davos.csv")}

name.of.file <- "../../data/re_ml_02/daily_fluxes.laegern.csv"

# If do not exists such a file, create it!
if (!file.exists(name.of.file)){
  # Access to the data
  url.2 <- "https://raw.githubusercontent.com/geco-bern/agds/main/data/FLX_CH
  -Lae_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv"
  # Read in the data directly from URL
  daily_fluxes.davos <- read.table(url.1, header = TRUE, sep = ",")
  # Write a CSV file in the respiratory
  write_csv(daily_fluxes.laegern, "../../data/re_ml_02/daily_fluxes.laegern.csv")
  # Read the file
  daily_fluxes.laegern <- read_csv("../../data/re_ml_02/daily_fluxes.laegern.csv")
  # If exists such a file, read it!
}else{daily_fluxes.laegern <- read_csv("../../data/re_ml_02/daily_fluxes.laegern.csv")}
```

## Data Overview

### Data cleaning

We can see that some columns contains -9999 as a value. Our quality
function changed that to NA. Than we use ymd() from the "lubridate" package
to rewrote the date in a proper way. Further, we want only columns which
contains good quality. For that we check selected columns with their
quality control columns. If the proportion of good measurement is less than
80%, then we overwrite the value with NA (and do not drop the row!). Now we
know that our data has a high quality and we can perform our analyses with
it.

Here, we work with two location (Davos and Lägern). But we do not want to
do everything twice. That why we define a new data frame which contains all
information about the two locations. We use .id = "id" because we must know
where the values come from. If we know that, we can use the filter function
from the package "dplyr" and analyse our data efficient.

```{r Dataquality, error=FALSE, message=FALSE, warning=FALSE}
# Load the function in the file (we use the function from another markdown again)
source("../../R/re_ml_01/function.use.good.quality.only.R")

# Function call to clean the data of Davos
daily_fluxes.davos <- use.good.quality(daily_fluxes.davos)
# Function call to clean the data of Lägern
daily_fluxes.laegern <- use.good.quality(daily_fluxes.laegern)

# We create a new data frame with bind_rows. We us "id" as an identifier. 
daily_fluxes_both <- bind_rows(daily_fluxes.davos, daily_fluxes.laegern, .id = "id")

# We check the again. Now our dataset contains NAs and only the columns of interest
# Load the function
source("../../R/general/function.visualize.na.values.R")

# Function call
visualize.na.values.without.groups(daily_fluxes_both)
```

## Split the data

Here we split our data in a training set and a test set. First we will
split the data (80 % training and 20 % test). We set seed for a
pseudo-random choice (reproducibility).

```{r error=FALSE, message=FALSE, warning=FALSE}
# For reproducibility (pseudo-random)
set.seed(123)  
# Split 80 % to 20 % 
split_davos <- rsample::initial_split(daily_fluxes_both|> 
                                        dplyr::filter(id == 1) , 
                                        prop = 0.8, strata = "VPD_F")

split_laegern <- rsample::initial_split(daily_fluxes_both|> 
                                          dplyr::filter(id == 2), 
                                          prop = 0.8, strata = "VPD_F")

split_both <- rsample::initial_split(daily_fluxes_both, prop = 0.8, strata = "VPD_F")

# Split Davos
daily_fluxes_davos_train <- rsample::training(split_davos)
daily_fluxes_davos_test <- rsample::testing(split_davos)

# Split Lägern
daily_fluxes_laegern_train <- rsample::training(split_laegern)
daily_fluxes_laegern_test <- rsample::testing(split_laegern)

# Split pooled
daily_fluxes_both_train <- rsample::training(split_both)
daily_fluxes_both_test <- rsample::testing(split_both)
```

For KNN, we use k = 8a again (which is a random choice)). The last code
chunk in this workflow will show you, which k is the optimal one (we do not
want to spoiler here. That is why you should use k = 8 first). We use the
method "cv" (cross validation). To evaluate the model, we want 10
validation sets.

```{r error=FALSE, message=FALSE, warning=FALSE}
# Load the function in the file.
source("../../R/re_ml_02/function.knn.cv.model.R")

# Function call for Davos
knn.model.davos <- knn.cv.model(daily_fluxes_davos_train, 8, 10)
# Function call for Lägern
knn.model.laegern <- knn.cv.model(daily_fluxes_laegern_train, 8, 10)
# Function call for Davos and Lägern
knn.model.both <- knn.cv.model(daily_fluxes_both_train, 8, 10)
```

We evaluate our models. For that we make seven different calls:

1.  Davos $\Longrightarrow$ Davos
2.  Davos $\Longrightarrow$ Lägern
3.  Lägern $\Longrightarrow$ Lägern
4.  Lägern $\Longrightarrow$ Davos
5.  Davos+Lägern $\Longrightarrow$ Davos
6.  Davos+Lägern $\Longrightarrow$ Lägern
7.  Davos+Lägern $\Longrightarrow$ Davos+Lägern

```{r error=FALSE, message=FALSE, warning=FALSE}
# Load the function
source("../../R/re_ml_01/function.evaluation.model.R")

P.1 <- eval_model(knn.model.davos, daily_fluxes_davos_train, 
                  daily_fluxes_davos_test, c("Davos (knn: k=8)"), c("Davos (knn: k=8)"))

P.2 <- eval_model(knn.model.davos, daily_fluxes_davos_train, 
                  daily_fluxes_laegern_test, c("Davos (knn: k=8)"), c("Lägern (knn: k=8)"))
# Function call for KNN
P.3 <- eval_model(knn.model.laegern, daily_fluxes_laegern_train, 
                  daily_fluxes_laegern_test, c("Lägern (knn: k=8)"), c("Lägern (knn: k=8)"))

P.4 <- eval_model(knn.model.laegern, daily_fluxes_laegern_train, 
                  daily_fluxes_davos_test, c("Lägern (knn: k=8)"), c("Davos (knn: k=8)"))

P.5 <- eval_model(knn.model.both, daily_fluxes_both_train, 
                  daily_fluxes_both_test, c("Davos and Lägern (knn: k=8)"), 
                  c("Davos and Lägern (knn: k=8)"))

P.6 <- eval_model(knn.model.both, daily_fluxes_both_train,
                  daily_fluxes_davos_test, c("Davos and Lägern (knn: k=8)"), 
                  c("Davos (knn: k=8)"))

P.7 <- eval_model(knn.model.both, daily_fluxes_both_train, 
                  daily_fluxes_laegern_test, c("Davos and Lägern (knn: k=8)"), 
                  c("Lägern (knn: k=8)"))
```

Train a single model with training data pooled from both sites and predict
with this single model on the test data of both sites. How do the model
metrics on the test set compare to the true out-of-sample setup above?
Interpret differences. Is it a valid approach to perform model training
like this? Use your knowledge about structure in the data and its relevance
for the model training setup.

```{r error=FALSE, message=FALSE, warning=FALSE}
cowplot::plot_grid(P.1, P.2, nrow = 2)

cowplot::plot_grid(P.3, P.4, nrow = 2)

cowplot::plot_grid(P.6, P.7, nrow = 2)

cowplot::plot_grid(P.5, NULL, nrow = 2)
```

```{r error=FALSE, message=FALSE, warning=FALSE}
# Load the function into the file
source("../../R/re_ml_02/function.parameter.extracter.cv.R")

# Define a sequence for k. Use 1,2,3,4 to show the curve at the beginning
my.sequence.extracter <- c(1,2,3,4,seq(5, to = 100, by = 5))

# Function call to determine the optimal k
parameter.extracter.knn.cv(my.sequence.extracter, 
                   daily_fluxes_both_train, daily_fluxes_davos_test, 10)
```

# Discussion

## Model

### Davos

Get information about the characteristics of the two sites. What are the
differences in terms of climate, vegetation, altitude, etc. between the
Davos and Lägern sites? Interpret biases of the out-of-sample predictions
with a view to the site characteristics.

### Lägern

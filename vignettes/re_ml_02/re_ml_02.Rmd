---
title: "Exercise_5"
author: "Patrick Bigler"
date: "2023-04-24"
output:
  pdf_document: default
  html_document: default
editor_options: 
  markdown: 
    wrap: 75
---

# Report Exercise: "Machine Learning 2"

Course: Applied Geo-data Science at University of Bern (Institute of
Geography)

Supervisor: Prof. Dr. Benjamin Stocker

Adviser: Dr. Koen Hufkens, Pepa Aran, Pascal Schneider

[You have questions to the workflow? Contact the Author:]{.underline}

Author: Bigler Patrick
([patrick.bigler1\@students.unibe.ch](mailto:patrick.bigler1@students.unibe.ch){.email})

Matriculation number: 20-100-178

Reference: Report Exercise 5 (Chapter 10)

## Programming and data evaluation

### Packages

The following code chunk contains all packages we need. Important is the
package "conflicted". It enables us to chose if different functions have
the same call but do not make the same thing (a function in a certain
package can have the same name as a function from another package).

```{r Load_packages, error=FALSE, message=FALSE, warning=FALSE}
source("../../R/general/packages.R")
```

### Original source of the file

Use the URL in the code chuck to get access to the data

```{r Load_and_read_data, error=FALSE, message=FALSE, warning=FALSE}
name.of.file <- "../../data/re_ml_02/daily_fluxes.davos.csv"

# If do not exists such a file, create it!
if (!file.exists(name.of.file)){
  # Access to the data
  url.1 <- "https://raw.githubusercontent.com/geco-bern/agds/main/data/FLX_C
  -Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv"
  # Read in the data directly from URL
  daily_fluxes.davos <- read.table(url.1, header = TRUE, sep = ",")
  # Write a CSV file in the respiratory
  write_csv(daily_fluxes.davos, "../../data/re_ml_02/daily_fluxes.davos.csv")
  # Read the file
  daily_fluxes.davos <- read_csv("../../data/re_ml_02/daily_fluxes.davos.csv")
  # If exists such a file, read it only!
  }else{daily_fluxes.davos <- read_csv("../../data/re_ml_02/daily_fluxes.davos.csv")}

name.of.file <- "../../data/re_ml_02/daily_fluxes.laegern.csv"

# If do not exists such a file, create it!
if (!file.exists(name.of.file)){
  # Access to the data
  url.2 <- "https://raw.githubusercontent.com/geco-bern/agds/main/data/FLX_CH
  -Lae_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv"
  # Read in the data directly from URL
  daily_fluxes.davos <- read.table(url.1, header = TRUE, sep = ",")
  # Write a CSV file in the respiratory
  write_csv(daily_fluxes.laegern, "../../data/re_ml_02/daily_fluxes.laegern.csv")
  # Read the file
  daily_fluxes.laegern <- read_csv("../../data/re_ml_02/daily_fluxes.laegern.csv")
  # If exists such a file, read it only!
  }else{daily_fluxes.laegern <- read_csv("../../data/re_ml_02/daily_fluxes.laegern.csv")}
```

### Data cleaning

For a good analysis, we should always do a quality control. That we do
next. First we call the first few rows. We can see that some columns
contains -9999 as a value. Our quality function changed that to NA. Than we
use ymd() from the lubridate package to rewrote the date in a proper way.
Further we want only columns which contains good quality. For that we check
selected columns with their quality control column.If the proportion of
good measurement is less than 80%, then we discard this variable. After
that we discard all quality-control columns. Now we know that our dataset
is of high enough quality to perform analyses with it.

```{r Dataquality, error=FALSE, message=FALSE, warning=FALSE}
# Load the function in the file (we use the function from another markdown again)
source("../../R/re_ml_01/function.use.good.quality.only.R")

# Load the function
source("../../R/general/function.visualize.na.values.R")

# Call the first 6 rows of all columns. There is -9999 instead of NA and lot of columns
head(daily_fluxes.davos)
head(daily_fluxes.laegern)

# Function call to clean the data
daily_fluxes.davos <- use.good.quality(daily_fluxes.davos)

daily_fluxes.laegern <- use.good.quality(daily_fluxes.laegern)

# We check the again. Now our dataset contains NAs and only the columns of interest
visualize.na.values.without.groups(daily_fluxes.davos)
visualize.na.values.without.groups(daily_fluxes.laegern)
```

### Split the data

Here we split our data in a training set and a test set. First we will
split the data (80 % training and 20 % test). After we split the data we
can calculate our model. For KNN, we use k = 8. This choice is random. The
last code chunk in this workflow will show you, which k is the optimal one
(we do not want to spoiler here. That is why you should use k = 8 first).

```{r error=FALSE,message=FALSE, warning=FALSE}
# For reproducibility (pseudo-random)
set.seed(123)  
# Split 80 % to 20 % 
split_davos <- rsample::initial_split(daily_fluxes.davos, prop = 0.8, strata = "VPD_F")
split_laegern <- rsample::initial_split(daily_fluxes.laegern, prop = 0.8, strata = "VPD_F")

# Split davos
daily_fluxes_davos_train <- rsample::training(split_davos)
daily_fluxes_davos_test <- rsample::testing(split_davos)

# Split Lägern
daily_fluxes_laegern_train <- rsample::training(split_laegern)
daily_fluxes_laegern_test <- rsample::testing(split_laegern)

# Load the function in the file.
source("../../R/re_ml_02/function.knn.cv.model.R")

knn.model.davos <- knn.cv.model(daily_fluxes_davos_train, 8)
knn.model.laegern <- knn.cv.model(daily_fluxes_laegern_train, 8)
```

Compare within-site predictions and across-site predictions on the test set
for both sites, considering different metrics. For across-site predictions,
make sure to implement a train and test setup that enables a true
out-of-sample prediction test.

```{r}

source("../../R/re_ml_01/function.evaluation.model.R")

# Function call for linear regression model
eval_model(knn.model.davos, daily_fluxes_davos_train, daily_fluxes_davos_test)

# Function call for KNN
eval_model(mod.knn_laegern, daily_fluxes_laegern_train, daily_fluxes_laegern_test)

# Across



```

Train a single model with training data pooled from both sites and predict
with this single model on the test data of both sites. How do the model
metrics on the test set compare to the true out-of-sample setup above?
Interpret differences. Is it a valid approach to perform model training
like this? Use your knowledge about structure in the data and its relevance
for the model training setup.

```{r}

```

-   Get information about the characteristics of the two sites. What are
    the differences in terms of climate, vegetation, altitude, etc. between
    the Davos and Laegern sites? Interpret biases of the out-of-sample
    predictions with a view to the site characteristics.

because we do not need a

```{r}
new.table <- bind_rows(daily_fluxes.davos, daily_fluxes.laegern, .id = "id")
```

Auswerten

. alles mit davos

. alles mit lägern

. alles mit allem

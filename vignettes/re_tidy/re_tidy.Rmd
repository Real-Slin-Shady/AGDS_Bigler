---
title: 'Report Exercise: re_tidy'
author: "Patrick Bigler"
date: "2023-04-03"
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
  '': default
editor_options:
  markdown:
    wrap: 75
---

Course: Applied Geo-Data Science at the University of Bern (Institute of
Geography)

Supervisor: Prof. Dr. Benjamin Stocker

Adviser: Dr. Koen Hufkens, Pepa Aran, Pascal Schneider

Further information: <https://geco-bern.github.io/agds/>

[Do you have questions about the workflow? Contact the author:]{.underline}

Author: Bigler Patrick (patrick.bigler1\@students.unibe.ch)

Matriculation number: 20-100-178

Reference: Report Exercise 2 (Chapter 3)

# Introduction

## Objectives

Handling data is key in science. It takes practice and experience to be
able to process data efficiently and without errors. This exercise serves
as an introduction to "Tidyverse" and has the goal of gaining practical
experience. With a realistic problem, the following goals should be
achieved:

-   Read and transform tabulated data

-   Understand the 'tidy' data concept

-   Select variables

-   Aggregate data

-   Handle bad and/or missing data

## Theory

The topic of this exercise is the "Logarithmic Respond Ratio" (LRR). The
LRR is the natural logarithm $(log())$ of the response ratio
$(\frac{x_{elevated}}{x_{ambient}})$. The LRR describes the elevated
concentration of a quantity (e.g. CO2 or nitrogen) to the ambient
concentration and is defined as followed:

$$LRR = \log\left(\frac{x_{eluvated}}{x_{ambient}}\right)$$

In this exercise, we worked with a data set that includes data of soil
organic carbon measurements in experiments where ecosystems are exposed to
ambient (low) and elevated (high) $CO_2$-concentrations. The mean soil
organic carbon of multiple samples is recorded within each experiment for
different dates.

## Original source of the file

The data originate from a paper by Groenigen et al. (2014). In this
exercise, we take a close look to the $CO_2$ - concentrations
$(\: [\frac{g}{m^{2}}])$ in the experiments and calculate the LRR. For
scientific reproducibility, you will find the original source in the
following article (or in the folder "data-raw"):

*Groenigen, Kees Jan van, Xuan Qi, Craig W. Osenberg, Yiqi Luo, and Bruce
A. Hungate. "Faster Decomposition Under Increased Atmospheric CO2 Limits
Soil Carbon Storage." Science 344, no. 6183 (May 2, 2014):
508--9.Â <https://doi.org/10.1126/science.1249534>.*

# Method

## Software

### EXCEL: Editing the file manually

Unfortunately, the original file is not well structured. It has several
headings and empty spaces which complicates reading the file and therefore,
we must the file edit manually. The software EXCEL (MS Office 360 with a
license from the University of Bern, status: 2023-05-07) is used for this
task. The following points were changed manually:

1.  Filled the gaps between two experiments with the name of the
    experiment.

2.  Removed the co- and sub-headers and all comments

### R: Evaluation of the data

After the manual editing, the xlsx file can be read with the software
R-Studio (Version 2022.12.0+353). This software uses the language R to
handle the data. For efficient processing of the data, we use the R-package
"Tidyverse" (and others).

## LRR for each experiment

For the first task, we calculate the LRR for each experiment. But we can do
this in two different ways:

[Method 1:]{.underline}

First, we group the database by 'Experiment'. Second, we calculate the mean
for the columns "mean ambient CO2" and "mean increased CO2" (now we have a
average for each experiment). Third, we calculate the LRR for each
experiment by using the values of the second step.

[Method 2:]{.underline}

First, we calculate the LRR for each row (now, every sample date has a
LRR). Second, we group the database by "Experiment". Third, we take the
average of all LRRs of each experiment by using the values of the first
step.

Although the results of both methods are the LRR for each experiment, they
will be in general different. Therefore, it is important which method we
chose. In this case, it is more meaningful to use method 2 because we use
$CO_2$-concentrations that have been measured during the experiment. It
makes more sense that we take this into account. If we use method 1, we
would calculate the LRR with a $CO_2$-concentration that never existed in
the experimental setup. In this exercise, we will calculate the LRR with
both methods because we want to demonstrate, that there is a difference.

## LRR for each phase

In the second task, we calculate the LRR for each phase. Each phase
corresponds to the duration of the experiments. We define three phases:

1)  Phase "early" $\Longrightarrow$ lesser than 3 years

2)  Phase "mid" $\Longrightarrow$ between 3 and 6 years

3)  Phase "late" $\Longrightarrow$ greater than 6 years

For an efficient way to process the data, we use "Tidyverse" again. Here,
we are confronted with the same problem as in the first task because there
are again two methods to calculate the LRR. We chose method 2 again (same
considerations and the same argumentation as for task one).

# Programming and data evaluation

## Packages

The following code chunk contains all packages we need. Important is the
package "conflicted". It enables us to choose if different functions have
the same call, but do not make the same thing (a function in a certain
package can have the same name as a function from another package). In this
case, we will set preferences.

```{r Packages, error=FALSE, message=FALSE, warning=FALSE}
# Load the packages
source("../../R/general/packages.R")
```

## Read the file

The following code chunk shows us, how we can read the file. First, the
xlsx-file has several sheets. We extract the sheet of interest and save it
on a variable. But we want a CSV-file and so we create a new folder and
save the new file into it. We read the CSV-file again for further editing.
But we must do this only once. If the file exists, then we can read it
directly. That is why we implemented an if-else statement.

```{r read_file, error=FALSE, message=FALSE, warning=FALSE}
# We want to know, if a certain file already exists
name.of.file <- "../../data/re_tidy/re_tidy.new.data.csv"

# If do not exists such a file, create it!
if (!file.exists(name.of.file)){
  # Read a certain sheet of the xlsx file
  raw <- read_xlsx("../../data-raw/re_tidy.raw.data/data.groenigen.xlsx", 
         "Database S1",range = NULL, col_names = TRUE, col_types = NULL, na = "")

  # Convert the xlsx to a csv file
  write_csv(raw, "../../data/re_tidy.new.data.csv")
  
  # Read the file
  raw.data <- read_csv("../../data/re_tidy/re_tidy.new.data.csv", 
              show_col_types = FALSE)

  # If exists such a file, read it only!
  }else{raw.data <- read_csv("../../data/re_tidy/re_tidy.new.data.csv", 
                    show_col_types = FALSE)}
```

## Data Overview

Information about the data is key. That is why we make some calls. We
change the names of the columns we need. Now, we can refer to them better.
Furthermore, we want to know which class the columns have and whether there
are missing values. We can see there are many NA (23.6%). The high
frequency of NA in "value treatment" is not a problem because we do not use
this column. The horizontal lines imply that there are empty rows. But this
is not a problem at all. R will ignore them and we are good to go.

```{r Quality_control, error=FALSE, message=FALSE, warning=FALSE}
# Check the class of each column
as.data.frame(sapply(raw.data, class))

# Return the important statistical parameters
summary(raw.data)

# Change the names of the two columns that are needed later on
raw.data <- raw.data|>
  rename("mean ambient CO2" = `ambient CO2...6`,
         "mean increased CO2" = `increased CO2...7`)

# Load the function
source("../../R/general/function.visualize.na.values.R")

# Function call
visualize.na.values.without.groups(raw.data, c("Problems with empty rows and value treatment!"))
```

## Quality Control

Now we want to edit the data. We wrote a function to wrangle our data.
After the call we want to know, whether the function has worked and if
there an improvement. That is why we make a quality control call. We can
see the function did exactly what we wanted it to do. The new table DB_S1
contains only selected columns. Further, we used bind_rows() to add a new
column with the corresponding phase for each row. Now we are sure that our
data has a good quality.

```{r Calculate_the_LRR, error=FALSE, message=FALSE, warning=FALSE}
# Load the function to prepare the data set
source("../../R/re_tidy/function.data.preparation.for.LRR.R")

# Function call
DB_S1 <- data.preparation.for.LRR(raw.data)

# Function call
visualize.na.values.without.groups(DB_S1, c("Everything ok!"))
```

## LRR calculation for each experiment

Now we calculate the LRR for each experiment and use knitr::kable() for a
proper html outcome...

```{r}
# Load the function to calculate the LRR by experiment
source("../../R/re_tidy/function.LRR.by.experiment.R")

# Function call to calculate the LRR for each experiment and save it as a HTML kable
LRR.by.experiment(DB_S1, 1)
```

## LRR calculation for each phase

...and do the same for each phase.

```{r}
# Load the function to calculate the LRR by phase
source("../../R/re_tidy/function.LRR.by.phase.R")

# Function call to calculate the LRR for each phase and save it as a HTML kable
LRR.by.phase(DB_S1, 2)
```

# Discussion

The result is rounded to 3 digits. As you can see, the results of Method 1
and Method 2 are different. In this case, Method 2 is more meaningful than
Method 1 (see theory and method). But this is not always the case. It is
therefore important to consider what exactly you want to analyze and what
is the context of the experiment.

---
title: "Report_Exercise_4"
author: "Patrick Bigler"
date: "2023-05-01"
output: html_document
---

```{r Packages}
source("../R/packages.R")
```


```{r Read_the_file}
# Quiet a message because we know it already
options(readr.show_col_types = FALSE)

# Read the file
daily_fluxes <- data.frame(read_csv("../data/DAV_Fluxnet_2015.csv"))
```


```{r Dataquality}
# Load the function in the file
source("../R/Exercise_4/function.use.good.quality.only.R")

# Function call
daily_fluxes <- use.good.quality.only(daily_fluxes)
```


```{r splitting_data_in_train_and_test}
# Load the function in the file
source("../R/Exercise_4/function.split.train.and.test.R")

# Function call for KNN with k = 8
mod.knn <- knn.model(8)

# Function call for lm
mod.lm <- lm.model()
```


```{r model_evaluation}
# Load the function
source("../R/Exercise_4/function.evaluation.model.R")

# Function call for linear regression model
eval_model(mod = mod.lm, df_train = daily_fluxes_train, df_test = daily_fluxes_test)

# Function call for KNN
eval_model(mod = mod.knn, df_train = daily_fluxes_train, df_test = daily_fluxes_test)
```

```{r visualization_of_generalisability}
# Load the function into the file
source("../R/Exercise_4/function.different.k.R")

my.sequence <- c(1,2,3,4,seq(10, to = 90, by = 10), 96,97,98,99,100)
different.k(my.sequence, daily_fluxes_train, daily_fluxes_test)
```


#Discussion
In this part we discuss the differences between a lm model and a KNN model. 
Further we will take a closer look to the KNN algorithm and the roll of k.

##Why is the difference between the evaluation on the training and the test set larger for the KNN model than for the linear regression model?
A lm model use all predictors to calculate a multivariate regression model.
We take a close look to the formula:

y = a_1*x_1 + a_2*x_2 + ...+a_n*x_n + intercept

Obviously, a lm model do not look for any underlying pattern. It creates a linear
combination and all predictors should be linear independent. If we want apply the
model then we must consider this fact. To create a lm model we use the training data.
But we calculate only a regression and therefore it is not possible that RSQ = 1
(only if the predictor is also the target and the predictors are linear dependent).
Therefore, the lm model will always have a bias. Most likely the RMSE and MAE will 
increase if we make predictions because the lm model do not know anything of 
the underlying pattern.

The situation of KNN is different. KNN calculate a "local regression". It use not 
only all predictors. It uses k neighbours to calculate a local regression. The KNN
model look for an underlying pattern. That is why the RSQ in the training data is
lower than for the lm model. If we want to do a prediction the KNN has a adventage 
over the lm. KNN "knows" the underlying pattern and the RMSE and MAE will not 
increase fast.

##Why does the evaluation on the test set indicate a better model performance of the KNN model than the linear regression model?
Because the RMSE and MAE in the KNN is lower than in the lm model. Further, RSQ
is higher in the KNN model than in the lm model. The KNN model performes a predictions
whit a low bias (MAE) and low variance (high RSQ) and is better than the lm model
with a higher bias (MAE is higher) and more variance (lower RSQ). It follows that 
the KNN model has the bestter bias-variance trade off than lm model But be careful:
RMSE and RSQ in the KNN model dependence directly from k.

##How would you position the KNN and the linear regression model along the spectrum of the bias-variance trade-off?
For the lm model the variance increase

The KNN model seems overfitted. The RSQ in the training data is high and jumps down
for the test data. The RMSE increase from the training data to the test data.
This conclude that the KNN model is more on the bias side in the bias-variance trade off.

The lm model is more or less the same. 

#Visualize temporal variations of observed and modlled GPP for both models, covering all available dates.

```{r Visualization}
# Load the function into the file
source("../R/Exercise_4/function.time.variation.R")

# Function call
time.variation(mod.knn, mod.lm, daily_fluxes_test)
```


#Discuss "K"

The "k" in KNN is a parameter that refers to the number of nearest neighbors.
Here, we use MAE instead of RMSE. Although the values are different, the flows 
are synchronous. That means that for both, MAE and RMSE are hyperbolas and have
their global minima at the same k.

##Hypothesis:
The lower we chose k the higher is RSQ in the training data but the higher the variance 
in the test data and therefore the higher the MAE.

Explanation:
Let k = 1. Then the training data would be perfectly predicted because only one   
(the nearest) neighbour would be taken into account. The bias would be zero
and therefore is RSQ = 1 and the MAE is 0 as well. But the model would be 
totally overfitted. That means there is a bias-variance trade off. If the bias 
in the training data is low, then is the variance in the test data is in general high. 

Let k = N. Then would follow: RSQ is an element of (0,1] and the MAE
an element of [0, inf). But we do not know where it is. However, the model tends 
to be underfitted because there are to many neighbours. We see that in the increasing
of the MAE with increaing of k.

Conclusion: We want a model with zero bias and zero variance. But this seems impossible
so we have to find the model with the best bias-variance-trade off.

## Showing model generalisability as a function of model complexity and optimal k
The hypothesis is not fully true. RSQ is a quantity to describe the variance. Or 
better, it describes how many procent of the variance explains the model. For the 
best bias-variance tradeoff we want the k where the bias in the test data is lowest 
(low MAE) and the variance should be 
On figure xx you can see, that the model is for k = 0 totally overfitted. In the 
training data the RSQ is 1 and it follows that the bias must be 0. But in the test data
the MAE is at a global maximum. The model is useless for any predictions and the 
trade off is on the side with to much variance.

For k = 200 the RSQ is lowest in the training data. The MAE increase for both 
data sets but is not at a maximum. The model is not suitable for predictons because
the trade-off is on the side with to much bias.

The optimal k is there, where the trade off is best. Generalizability means that we 
want the model with the lowest MAE in the test data (low bias) and the highest RSQ
(low variance). For that we mark the minimum of the RMSE test data hyperbola
(green point = 25).

```{r visualization_generalisability_optimal_k}
# Load the function into the file
source("../R/Exercise_4/function.parameter.extracter.R")

# Define a sequence for k. Use 1,2,3,4 to show the curve at the beginning
my.sequence.extracter <- c(1,2,3,4,seq(5, to = 200, by = 5))

# function call
paramter.extracter(my.sequence.extracter, daily_fluxes_train, daily_fluxes_test)
```

